{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import re\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Reading data into a pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: FutureWarning: from_csv is deprecated. Please use read_csv(...) instead. Note that some of the default arguments are different, so please refer to the documentation for from_csv when changing your function calls\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame.from_csv('C:/Users/Adroit/GoogleDrive/MScA/nlp/assignment_2/Food_Inspections.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Dropping rows where we don't have any violations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(subset=['Violations'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Dropping rows where Result is not fail as we care about failed food inspections only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['Results'] == 'Fail']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Some restaurants have more than 1 violations. These violations are delimited by \"|\". We are applying regex to split all violations into a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Violations_list'] = df['Violations'].apply(lambda x: re.split(\"[|]+\", x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "violations = list()\n",
    "for violationlist in df['Violations_list'].tolist():\n",
    "    violations += violationlist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Removing violation information and keeping just the comments information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "violations_comments = list()\n",
    "\n",
    "for violation in violations:\n",
    "    violation_info = re.split(\"- Comments:\", violation)\n",
    "    if len(violation_info) > 1:\n",
    "        violations_comments.append(violation_info[1].strip().upper())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_violations = \",\".join(violations_comments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Finding the most frequently used word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<FreqDist with 76286 samples and 7633457 outcomes>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(',', 470378),\n",
       " ('AND', 330387),\n",
       " ('.', 291105),\n",
       " ('THE', 228205),\n",
       " ('IN', 203706),\n",
       " ('TO', 156344),\n",
       " ('OF', 141939),\n",
       " ('ALL', 113085),\n",
       " ('MUST', 108290),\n",
       " ('ON', 88879)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = nltk.tokenize.word_tokenize(all_violations)\n",
    "fdist = nltk.FreqDist(words)\n",
    "\n",
    "print(fdist)\n",
    "\n",
    "#fdist.items() - will give all words\n",
    "fdist.most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Cleaning the text to remove stop words and then counting again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<FreqDist with 19516 samples and 4183643 outcomes>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('must', 108290),\n",
       " ('food', 85730),\n",
       " ('clean', 84224),\n",
       " ('instructed', 68999),\n",
       " ('area', 63342),\n",
       " ('prep', 56990),\n",
       " ('observed', 54384),\n",
       " ('sink', 52765),\n",
       " ('floor', 45613),\n",
       " ('storage', 43406),\n",
       " ('repair', 41818),\n",
       " ('violation', 39562),\n",
       " ('shall', 39047),\n",
       " ('provide', 37679),\n",
       " ('rear', 34545),\n",
       " ('maintain', 32925),\n",
       " ('remove', 32680),\n",
       " ('water', 30256),\n",
       " ('cooler', 29058),\n",
       " ('serious', 28495),\n",
       " ('door', 27402),\n",
       " ('equipment', 27295),\n",
       " ('walls', 26586),\n",
       " ('areas', 24935),\n",
       " ('inside', 23860),\n",
       " ('ice', 22128),\n",
       " ('citation', 22031),\n",
       " ('replace', 21853),\n",
       " ('pest', 21707),\n",
       " ('front', 21681),\n",
       " ('hand', 21052),\n",
       " ('floors', 21005),\n",
       " ('compartment', 20646),\n",
       " ('room', 19479),\n",
       " ('wall', 19227),\n",
       " ('found', 18704),\n",
       " ('control', 18359),\n",
       " ('premises', 17853),\n",
       " ('kitchen', 17783),\n",
       " ('manager', 17552),\n",
       " ('detail', 17456),\n",
       " ('machine', 17285),\n",
       " ('basement', 17227),\n",
       " ('hot', 17192),\n",
       " ('stored', 16654),\n",
       " ('service', 16652),\n",
       " ('ceiling', 16379),\n",
       " ('droppings', 16165),\n",
       " ('behind', 16105),\n",
       " ('grease', 15816)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "words = nltk.tokenize.word_tokenize(all_violations)\n",
    "\n",
    "stopwords = set(nltk.corpus.stopwords.words('english'))\n",
    "\n",
    "# Remove punctuation\n",
    "words = [word for word in words if word.isalpha()]\n",
    "\n",
    "# Lowercase all words (default_stopwords are lowercase too)\n",
    "words = [word.lower() for word in words]\n",
    "\n",
    "# Remove stopwords\n",
    "words = [word for word in words if word not in stopwords]\n",
    "\n",
    "fdist = nltk.FreqDist(words)\n",
    "\n",
    "print(fdist)\n",
    "\n",
    "fdist.most_common(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "porter = nltk.PorterStemmer()\n",
    "lancaster = nltk.LancasterStemmer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Porter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "porter_stemmed_words = [porter.stem(t) for t in words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<FreqDist with 14488 samples and 4183643 outcomes>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('must', 108293),\n",
       " ('clean', 106435),\n",
       " ('food', 100134),\n",
       " ('area', 88278),\n",
       " ('instruct', 69109),\n",
       " ('floor', 66850),\n",
       " ('sink', 62278),\n",
       " ('prep', 57258),\n",
       " ('observ', 54691),\n",
       " ('provid', 46054),\n",
       " ('wall', 45813),\n",
       " ('violat', 45081),\n",
       " ('repair', 43673),\n",
       " ('storag', 43466),\n",
       " ('cooler', 40940),\n",
       " ('maintain', 40534),\n",
       " ('shall', 39048),\n",
       " ('remov', 35785),\n",
       " ('door', 35563),\n",
       " ('rear', 34549),\n",
       " ('water', 30272),\n",
       " ('equip', 28803),\n",
       " ('seriou', 28503),\n",
       " ('store', 27393),\n",
       " ('sanit', 26549),\n",
       " ('insid', 23870),\n",
       " ('hand', 23796),\n",
       " ('room', 23625),\n",
       " ('manag', 23106),\n",
       " ('replac', 23019),\n",
       " ('ceil', 22570),\n",
       " ('ice', 22190),\n",
       " ('citat', 22136),\n",
       " ('use', 22078),\n",
       " ('pest', 22038),\n",
       " ('front', 21682),\n",
       " ('compart', 21673),\n",
       " ('shelv', 21671),\n",
       " ('machin', 21155),\n",
       " ('detail', 19197),\n",
       " ('found', 18707),\n",
       " ('cook', 18663),\n",
       " ('control', 18438),\n",
       " ('wash', 18282),\n",
       " ('premis', 18168),\n",
       " ('kitchen', 17866),\n",
       " ('light', 17829),\n",
       " ('servic', 17804),\n",
       " ('rodent', 17426),\n",
       " ('basement', 17274)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fdist = nltk.FreqDist(porter_stemmed_words)\n",
    "\n",
    "print(fdist)\n",
    "\n",
    "fdist.most_common(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Lancaster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "lancaster_stemmed_words = [lancaster.stem(t) for t in words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<FreqDist with 12447 samples and 4183643 outcomes>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('cle', 114439),\n",
       " ('must', 108295),\n",
       " ('food', 100134),\n",
       " ('stor', 70887),\n",
       " ('prep', 69154),\n",
       " ('instruct', 69137),\n",
       " ('flo', 67358),\n",
       " ('are', 63342),\n",
       " ('sink', 62280),\n",
       " ('observ', 54690),\n",
       " ('provid', 46079),\n",
       " ('wal', 45825),\n",
       " ('viol', 45122),\n",
       " ('repair', 43673),\n",
       " ('cool', 41471),\n",
       " ('maintain', 40545),\n",
       " ('shal', 39059),\n",
       " ('remov', 35786),\n",
       " ('door', 35565),\n",
       " ('rear', 34549),\n",
       " ('wat', 30309),\n",
       " ('equip', 28804),\n",
       " ('sery', 28500),\n",
       " ('sanit', 27655),\n",
       " ('found', 25889),\n",
       " ('area', 24937),\n",
       " ('bas', 24262),\n",
       " ('serv', 24146),\n",
       " ('insid', 23871),\n",
       " ('hand', 23802),\n",
       " ('room', 23627),\n",
       " ('man', 23593),\n",
       " ('replac', 23022),\n",
       " ('us', 22854),\n",
       " ('ceil', 22577),\n",
       " ('ic', 22192),\n",
       " ('cit', 22157),\n",
       " ('pest', 22041),\n",
       " ('front', 21682),\n",
       " ('compart', 21681),\n",
       " ('shelv', 21671),\n",
       " ('prop', 21528),\n",
       " ('machin', 21159),\n",
       " ('op', 19245),\n",
       " ('detail', 19197),\n",
       " ('cook', 18814),\n",
       " ('wash', 18735),\n",
       " ('control', 18438),\n",
       " ('prem', 18169),\n",
       " ('kitch', 17883)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fdist = nltk.FreqDist(lancaster_stemmed_words)\n",
    "\n",
    "print(fdist)\n",
    "\n",
    "fdist.most_common(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Lancaster stemming does not seem like a good idea as it is difficult to interpret some of the words, such as cle, flo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Lammatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "wnl = nltk.WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatized_words = [wnl.lemmatize(t) for t in words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<FreqDist with 17864 samples and 4183643 outcomes>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('must', 108293),\n",
       " ('food', 100133),\n",
       " ('area', 88279),\n",
       " ('clean', 84229),\n",
       " ('instructed', 68999),\n",
       " ('floor', 66618),\n",
       " ('sink', 62278),\n",
       " ('prep', 56998),\n",
       " ('observed', 54384),\n",
       " ('wall', 45813),\n",
       " ('violation', 45077),\n",
       " ('storage', 43459),\n",
       " ('repair', 42047),\n",
       " ('cooler', 40940),\n",
       " ('shall', 39047),\n",
       " ('provide', 37679),\n",
       " ('door', 35562),\n",
       " ('rear', 34545),\n",
       " ('maintain', 32925),\n",
       " ('remove', 32694),\n",
       " ('water', 30269),\n",
       " ('equipment', 28592),\n",
       " ('serious', 28495),\n",
       " ('inside', 23868),\n",
       " ('hand', 23776),\n",
       " ('room', 23624),\n",
       " ('ceiling', 22569),\n",
       " ('citation', 22134),\n",
       " ('ice', 22128),\n",
       " ('pest', 22038),\n",
       " ('replace', 21853),\n",
       " ('front', 21682),\n",
       " ('compartment', 21660),\n",
       " ('machine', 21154),\n",
       " ('found', 18707),\n",
       " ('manager', 18384),\n",
       " ('control', 18368),\n",
       " ('premise', 18164),\n",
       " ('kitchen', 17866),\n",
       " ('detail', 17473),\n",
       " ('rodent', 17425),\n",
       " ('basement', 17274),\n",
       " ('hot', 17192),\n",
       " ('service', 17064),\n",
       " ('stored', 16654),\n",
       " ('droppings', 16165),\n",
       " ('behind', 16105),\n",
       " ('grease', 15823),\n",
       " ('interior', 15784),\n",
       " ('issued', 15366)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fdist = nltk.FreqDist(lemmatized_words)\n",
    "\n",
    "print(fdist)\n",
    "\n",
    "fdist.most_common(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Lemmatization gives us good overview of the common keywords which lead to failed inspection. All keywords are valid words from the english dictionary"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
